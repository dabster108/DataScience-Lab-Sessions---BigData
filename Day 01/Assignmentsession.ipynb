{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14996b14-a820-44a4-bef7-2e6fb107ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6046403c-5a29-474a-b984-87bda6f9fb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = 'python'\n",
    "os.environ['JAVA_HOME'] = '/Library/Java/JavaVirtualMachines/jdk-11.jdk/Contents/Home'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dccf6684-3555-4ddf-bcb3-59a68de04004",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/25 11:16:00 WARN Utils: Your hostname, Dikshantas-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.12.25.144 instead (on interface en0)\n",
      "25/11/25 11:16:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/25 11:16:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/11/25 11:16:01 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Weather Flights Data Analysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38076618-b2ec-4840-b2ea-956984af5bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = spark.read.csv(\n",
    "    \"/Users/dikshanta/Documents/Softwarica 2nd sem Fils/bigdata/data/nyc_weather.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f56ac59f-7e7c-400d-94f2-e807fe34a88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26115\n",
      "+------+----+-----+---+----+-----+-----+-----+--------+------------------+---------+------+--------+-----+-------------------+\n",
      "|origin|year|month|day|hour| temp| dewp|humid|wind_dir|        wind_speed|wind_gust|precip|pressure|visib|          time_hour|\n",
      "+------+----+-----+---+----+-----+-----+-----+--------+------------------+---------+------+--------+-----+-------------------+\n",
      "|   EWR|2013|    1|  1|   1|39.02|26.06|59.37|     270|10.357019999999999|       NA|   0.0|    1012| 10.0|2013-01-01 11:45:00|\n",
      "|   EWR|2013|    1|  1|   2|39.02|26.96|61.63|     250|           8.05546|       NA|   0.0|  1012.3| 10.0|2013-01-01 12:45:00|\n",
      "|   EWR|2013|    1|  1|   3|39.02|28.04|64.43|     240|           11.5078|       NA|   0.0|  1012.5| 10.0|2013-01-01 13:45:00|\n",
      "|   EWR|2013|    1|  1|   4|39.92|28.04|62.21|     250|12.658579999999999|       NA|   0.0|  1012.2| 10.0|2013-01-01 14:45:00|\n",
      "|   EWR|2013|    1|  1|   5|39.02|28.04|64.43|     260|12.658579999999999|       NA|   0.0|  1011.9| 10.0|2013-01-01 15:45:00|\n",
      "+------+----+-----+---+----+-----+-----+-----+--------+------------------+---------+------+--------+-----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "15\n",
      "root\n",
      " |-- origin: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- temp: string (nullable = true)\n",
      " |-- dewp: string (nullable = true)\n",
      " |-- humid: string (nullable = true)\n",
      " |-- wind_dir: string (nullable = true)\n",
      " |-- wind_speed: string (nullable = true)\n",
      " |-- wind_gust: string (nullable = true)\n",
      " |-- precip: double (nullable = true)\n",
      " |-- pressure: string (nullable = true)\n",
      " |-- visib: double (nullable = true)\n",
      " |-- time_hour: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(weather.count())\n",
    "weather.show(5)\n",
    "print(len(weather.columns))\n",
    "weather.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ac4edb3-6bc0-4c2f-88a6-86bc7ebdc5c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26115"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab119929-a5ec-4187-b96b-8bd4adff2ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+-----+---+----+-----+-----+-----+--------+------------------+------------------+------+--------+-----+-------------------+\n",
      "|origin|year|month|day|hour| temp| dewp|humid|wind_dir|        wind_speed|         wind_gust|precip|pressure|visib|          time_hour|\n",
      "+------+----+-----+---+----+-----+-----+-----+--------+------------------+------------------+------+--------+-----+-------------------+\n",
      "|   EWR|2013|    1|  1|   1|39.02|26.06|59.37|     270|10.357019999999999|                NA|   0.0|    1012| 10.0|2013-01-01 11:45:00|\n",
      "|   EWR|2013|    1|  1|   2|39.02|26.96|61.63|     250|           8.05546|                NA|   0.0|  1012.3| 10.0|2013-01-01 12:45:00|\n",
      "|   EWR|2013|    1|  1|   3|39.02|28.04|64.43|     240|           11.5078|                NA|   0.0|  1012.5| 10.0|2013-01-01 13:45:00|\n",
      "|   EWR|2013|    1|  1|   4|39.92|28.04|62.21|     250|12.658579999999999|                NA|   0.0|  1012.2| 10.0|2013-01-01 14:45:00|\n",
      "|   EWR|2013|    1|  1|   5|39.02|28.04|64.43|     260|12.658579999999999|                NA|   0.0|  1011.9| 10.0|2013-01-01 15:45:00|\n",
      "|   EWR|2013|    1|  1|   6|37.94|28.04|67.21|     240|           11.5078|                NA|   0.0|  1012.4| 10.0|2013-01-01 16:45:00|\n",
      "|   EWR|2013|    1|  1|   7|39.02|28.04|64.43|     240|14.960139999999999|                NA|   0.0|  1012.2| 10.0|2013-01-01 17:45:00|\n",
      "|   EWR|2013|    1|  1|   8|39.92|28.04|62.21|     250|10.357019999999999|                NA|   0.0|  1012.2| 10.0|2013-01-01 18:45:00|\n",
      "|   EWR|2013|    1|  1|   9|39.92|28.04|62.21|     260|14.960139999999999|                NA|   0.0|  1012.7| 10.0|2013-01-01 19:45:00|\n",
      "|   EWR|2013|    1|  1|  10|   41|28.04|59.65|     260|13.809359999999998|                NA|   0.0|  1012.4| 10.0|2013-01-01 20:45:00|\n",
      "|   EWR|2013|    1|  1|  11|   41|26.96|57.06|     260|14.960139999999999|                NA|   0.0|  1011.4| 10.0|2013-01-01 21:45:00|\n",
      "|   EWR|2013|    1|  1|  13| 39.2| 28.4|69.67|     330|          16.11092|                NA|   0.0|      NA| 10.0|2013-01-01 23:45:00|\n",
      "|   EWR|2013|    1|  1|  14|39.02|24.08|54.68|     280|13.809359999999998|                NA|   0.0|  1010.8| 10.0|2013-01-02 00:45:00|\n",
      "|   EWR|2013|    1|  1|  15|37.94|24.08|57.04|     290|           9.20624|                NA|   0.0|  1011.9| 10.0|2013-01-02 01:45:00|\n",
      "|   EWR|2013|    1|  1|  16|37.04|19.94|49.62|     300|13.809359999999998|20.714039999999997|   0.0|  1012.1| 10.0|2013-01-02 02:45:00|\n",
      "|   EWR|2013|    1|  1|  17|35.96|19.04|49.83|     330|           11.5078|                NA|   0.0|  1013.2| 10.0|2013-01-02 03:45:00|\n",
      "|   EWR|2013|    1|  1|  18|33.98|15.08|45.43|     310|12.658579999999999|25.317159999999998|   0.0|  1014.1| 10.0|2013-01-02 04:45:00|\n",
      "|   EWR|2013|    1|  1|  19|33.08|12.92|42.84|     320|10.357019999999999|                NA|   0.0|  1014.4| 10.0|2013-01-02 05:45:00|\n",
      "|   EWR|2013|    1|  1|  20|   32|15.08|49.19|     310|14.960139999999999|                NA|   0.0|  1015.2| 10.0|2013-01-02 06:45:00|\n",
      "|   EWR|2013|    1|  1|  21|30.02|12.92|48.48|     320|          18.41248|          26.46794|   0.0|    1016| 10.0|2013-01-02 07:45:00|\n",
      "+------+----+-----+---+----+-----+-----+-----+--------+------------------+------------------+------+--------+-----+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d781399-d8e0-47b6-99af-6b697c275b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weather.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad489817-ca5b-4712-acf5-b213ae0aaa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- origin: string (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- day: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- temp: string (nullable = true)\n",
      " |-- dewp: string (nullable = true)\n",
      " |-- humid: string (nullable = true)\n",
      " |-- wind_dir: string (nullable = true)\n",
      " |-- wind_speed: string (nullable = true)\n",
      " |-- wind_gust: string (nullable = true)\n",
      " |-- precip: double (nullable = true)\n",
      " |-- pressure: string (nullable = true)\n",
      " |-- visib: double (nullable = true)\n",
      " |-- time_hour: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce16daf3-2cb0-46c7-badf-9236d74f1b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----+\n",
      "|day|month|hour|\n",
      "+---+-----+----+\n",
      "|  1|    1|   1|\n",
      "|  1|    1|   2|\n",
      "|  1|    1|   3|\n",
      "|  1|    1|   4|\n",
      "|  1|    1|   5|\n",
      "+---+-----+----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+\n",
      "|wind_dir|\n",
      "+--------+\n",
      "|     270|\n",
      "|     250|\n",
      "|     240|\n",
      "|     250|\n",
      "|     260|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+\n",
      "|origin|\n",
      "+------+\n",
      "|   EWR|\n",
      "|   EWR|\n",
      "|   EWR|\n",
      "|   EWR|\n",
      "|   EWR|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+------+----+-----+\n",
      "|origin|year|month|\n",
      "+------+----+-----+\n",
      "|   EWR|2013|    1|\n",
      "|   EWR|2013|    1|\n",
      "|   EWR|2013|    1|\n",
      "|   EWR|2013|    1|\n",
      "|   EWR|2013|    1|\n",
      "+------+----+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------+\n",
      "|pressure|\n",
      "+--------+\n",
      "|    1012|\n",
      "|  1012.3|\n",
      "|  1012.5|\n",
      "|  1012.2|\n",
      "|  1011.9|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "weather.select(\"day\",\"month\",\"hour\").show(5)\n",
    "weather.select(\"wind_dir\").show(5)\n",
    "weather.select(weather.columns[0]).show(5)\n",
    "weather.select(weather.columns[0:3]).show(5)\n",
    "weather.select(weather.columns[-3]).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ebc319b4-b25b-4294-bb6f-6a0cdf6f2ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imporing the pyspark feature \n",
    "from pyspark.sql.functions import*\n",
    "from pyspark.sql.functions import*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c0b4647-d807-4ee4-9739-b50ec715976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.createOrReplaceTempView(\"weather_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8f49ee6-a0e2-420e-8e53-8aa8be54a2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+\n",
      "|year|month|origin|\n",
      "+----+-----+------+\n",
      "|2013|    1|   EWR|\n",
      "|2013|    1|   EWR|\n",
      "|2013|    1|   EWR|\n",
      "|2013|    1|   EWR|\n",
      "|2013|    1|   EWR|\n",
      "+----+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query1 = spark.sql(\"SELECT year, month, origin FROM weather_table\")\n",
    "query1.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae174e06-0496-424d-b56c-2521f59df2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|month|\n",
      "+-----+\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "|    1|\n",
      "+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = spark.sql(\"SELECT month FROM weather_table WHERE month = 1\")\n",
    "query2.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ac0f845-06c6-4f0c-af60-d06f761d2c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+------+\n",
      "|year|month|origin|\n",
      "+----+-----+------+\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "|2013|    2|   EWR|\n",
      "+----+-----+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month origin\n",
       "0  2013      2    EWR\n",
       "1  2013      2    EWR\n",
       "2  2013      2    EWR\n",
       "3  2013      2    EWR\n",
       "4  2013      2    EWR"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "query2 = query2.toPandas()\n",
    "query2.head()\n",
    "\n",
    "query3 = spark.sql(\"SELECT year, month, origin FROM weather_table WHERE month = 2\")\n",
    "query3.show()\n",
    "query3 = query3.toPandas()\n",
    "query3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff56bb3b-e5c6-49f2-9266-13a293800679",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Casting to unit-less dtype 'datetime64' is not supported. Pass e.g. 'datetime64[ns]' instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 32\u001b[0m\n\u001b[1;32m     25\u001b[0m weather_renamed_columns \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     26\u001b[0m     weather\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;241m.\u001b[39mwithColumnRenamed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisib\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvisibility\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     28\u001b[0m         \u001b[38;5;241m.\u001b[39mwithColumnRenamed(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecipitation\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Convert to Pandas\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m weather_renamed_columns_pd \u001b[38;5;241m=\u001b[39m \u001b[43mweather_renamed_columns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Preview\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(weather_renamed_columns_pd\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m))\n",
      "File \u001b[0;32m~/Documents/Softwarica 2nd sem Fils/BigData/pyspark_env/lib/python3.10/site-packages/pyspark/sql/pandas/conversion.py:251\u001b[0m, in \u001b[0;36mPandasConversionMixin.toPandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m should_check_timedelta \u001b[38;5;241m=\u001b[39m is_timedelta64_dtype(t) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pdf) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (t \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_timedelta64_dtype(t)) \u001b[38;5;129;01mor\u001b[39;00m should_check_timedelta:\n\u001b[0;32m--> 251\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[43mseries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m catch_warnings():\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PerformanceWarning\n",
      "File \u001b[0;32m~/Documents/Softwarica 2nd sem Fils/BigData/pyspark_env/lib/python3.10/site-packages/pandas/core/generic.py:6324\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6317\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   6319\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m   6320\u001b[0m     ]\n\u001b[1;32m   6322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6323\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6324\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6327\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Softwarica 2nd sem Fils/BigData/pyspark_env/lib/python3.10/site-packages/pandas/core/internals/managers.py:451\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    449\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Softwarica 2nd sem Fils/BigData/pyspark_env/lib/python3.10/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    355\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/Documents/Softwarica 2nd sem Fils/BigData/pyspark_env/lib/python3.10/site-packages/pandas/core/internals/blocks.py:511\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 511\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    513\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    515\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Softwarica 2nd sem Fils/BigData/pyspark_env/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:242\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    239\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Softwarica 2nd sem Fils/BigData/pyspark_env/lib/python3.10/site-packages/pandas/core/dtypes/astype.py:184\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/Documents/Softwarica 2nd sem Fils/BigData/pyspark_env/lib/python3.10/site-packages/pandas/core/arrays/datetimes.py:694\u001b[0m, in \u001b[0;36mDatetimeArray.astype\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    683\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .astype to convert from timezone-aware dtype to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimezone-naive dtype. Use obj.tz_localize(None) or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobj.tz_convert(\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTC\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m).tz_localize(None) instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtz \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_datetime64_dtype(dtype)\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m dtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m is_unitless(dtype)\n\u001b[1;32m    693\u001b[0m ):\n\u001b[0;32m--> 694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCasting to unit-less dtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime64\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not supported. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    696\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass e.g. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime64[ns]\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    697\u001b[0m     )\n\u001b[1;32m    699\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_period_dtype(dtype):\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_period(freq\u001b[38;5;241m=\u001b[39mdtype\u001b[38;5;241m.\u001b[39mfreq)\n",
      "\u001b[0;31mTypeError\u001b[0m: Casting to unit-less dtype 'datetime64' is not supported. Pass e.g. 'datetime64[ns]' instead."
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# rename_map = {\n",
    "#     \"visib\": \"visibility\",\n",
    "#     \"precip\": \"precipitation\"\n",
    "# }\n",
    "\n",
    "# weather_renamed = weather.select([\n",
    "#     col(c).alias(rename_map.get(c, c)) for c in }weather.columns\n",
    "# ])\n",
    "\n",
    "# for field in weather_renamed.schema.fields:\n",
    "#     dtype = str(field.dataType)\n",
    "\n",
    "#     if \"DecimalType\" in dtype:\n",
    "#         weather_renamed = weather_renamed.withColumn(field.name, col(field.name).cast(\"float\"))\n",
    "\n",
    "#     if \"TimestampType\" in dtype or \"DateType\" in dtype:\n",
    "#         weather_renamed = weather_renamed.withColumn(field.name, col(field.name).cast(\"string\"))\n",
    "\n",
    "# weather_pd = weather_renamed.toPandas()\n",
    "# print(weather_pd.head())\n",
    "\n",
    "\n",
    "weather_renamed_columns = (\n",
    "    weather\n",
    "        .withColumnRenamed(\"visib\", \"visibility\")\n",
    "        .withColumnRenamed(\"precip\", \"precipitation\")\n",
    ")\n",
    "\n",
    "# Convert to Pandas\n",
    "weather_renamed_columns_pd = weather_renamed_columns.toPandas()\n",
    "\n",
    "# Preview\n",
    "print(weather_renamed_columns_pd.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f680eabb-1c09-4490-b6d6-e55f33086ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50edd69d-9bf8-4c66-84fa-b229a05a9774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64717956-12c4-4202-8b60-7a640a6498da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3002ec-c245-4849-a75f-66fd2c628b52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a88e7a-e1a0-4458-8852-29c25f766cd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
